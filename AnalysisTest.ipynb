{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcba499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check - add this to your existing code\n",
    "def quick_diagnosis_209(processed_data):\n",
    "    work_209 = processed_data\n",
    "    print(f\"Punch Code 209 Summary:\")\n",
    "    print(f\"Total records: {len(work_209)}\")\n",
    "    print(f\"NoOfMan range: {work_209['NoOfMan'].min()} to {work_209['NoOfMan'].max()}\")\n",
    "    print(f\"NoOfMan mean: {work_209['NoOfMan'].mean():.2f}\")\n",
    "    print(f\"Days with 0 workers: {(work_209['NoOfMan'] == 0).sum()}\")\n",
    "    print(f\"Days with >5 workers: {(work_209['NoOfMan'] > 5).sum()}\")\n",
    "    \n",
    "    # Check recent data\n",
    "    recent = work_209.nlargest(10, 'Date')\n",
    "    print(f\"Recent 10 days:\")\n",
    "    print(recent[['Date', 'NoOfMan']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05c52bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  WorkType   Hours   NoOfMan  SystemHours  Quantity  \\\n",
      "0    2019-12-14       209   97.69  12.21125     0.163055      2204   \n",
      "1    2019-12-17       209  239.29  29.91125   115.320277     37657   \n",
      "2    2019-08-21       209   83.45  10.43125    56.451666     17539   \n",
      "3    2019-08-23       209   72.95   9.11875    37.546388     22999   \n",
      "4    2019-11-15       209  105.89  13.23625    59.047777     20015   \n",
      "...         ...       ...     ...       ...          ...       ...   \n",
      "1521 2021-04-07       209   67.98   8.49750    45.684722     21730   \n",
      "1522 2020-11-13       209   75.74   9.46750    45.157500     17356   \n",
      "1523 2024-11-28       209  139.81  17.47625    79.968611     23877   \n",
      "1524 2022-10-13       209   63.24   7.90500    42.677500     19435   \n",
      "1525 2021-11-19       209  131.74  16.46750    91.498888     27580   \n",
      "\n",
      "      ResourceKPI     SystemKPI  \n",
      "0       22.561163  13516.911471  \n",
      "1      157.369719    326.542746  \n",
      "2      210.173757    310.690564  \n",
      "3      315.270733    612.548935  \n",
      "4      189.016904    338.962802  \n",
      "...           ...           ...  \n",
      "1521   319.652839    475.651356  \n",
      "1522   229.152363    384.343685  \n",
      "1523   170.781775    298.579651  \n",
      "1524   307.321316    455.392185  \n",
      "1525   209.351753    301.424428  \n",
      "\n",
      "[1526 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('209.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11a294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punch Code 209 Summary:\n",
      "Total records: 1526\n",
      "NoOfMan range: 0.0 to 39.02625\n",
      "NoOfMan mean: 8.56\n",
      "Days with 0 workers: 41\n",
      "Days with >5 workers: 1276\n",
      "Recent 10 days:\n",
      "           Date   NoOfMan\n",
      "75   2025-05-21   6.86000\n",
      "79   2025-05-20   9.66250\n",
      "80   2025-05-19   9.01250\n",
      "78   2025-05-16   6.55625\n",
      "77   2025-05-15   7.05125\n",
      "103  2025-05-14   9.53000\n",
      "76   2025-05-13  11.18875\n",
      "1273 2025-05-12  11.36875\n",
      "801  2025-05-09   7.08875\n",
      "410  2025-05-08   5.12625\n"
     ]
    }
   ],
   "source": [
    "quick_diagnosis_209(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7bb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading models...\n",
      "Loaded 9 models\n",
      "=== PREDICTION PIPELINE DEBUG FOR WORK TYPE 209 ===\n",
      "\n",
      "1. MODEL VERIFICATION:\n",
      "   Model type: <class 'sklearn.pipeline.Pipeline'>\n",
      "   Is Pipeline: True\n",
      "   Pipeline steps: ['preprocessor', 'model']\n",
      "\n",
      "2. FEATURE COMPARISON:\n",
      "   Expected features from model: 32\n",
      "   First 10 expected: ['NoOfMan_lag_1', 'NoOfMan_lag_2', 'NoOfMan_lag_3', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7', 'IsWeekend_feat', 'NoOfMan_rolling_max_7', 'NoOfMan_rolling_min_7', 'NoOfMan_rolling_std_7', 'NoOfMan_same_dow_lag']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 10:57:43.220 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-05-26 10:57:43.222 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features we're providing: 32\n",
      "   Numeric: 28, Categorical: 4\n",
      "   Available in data: 0\n",
      "   Missing from data: 32\n",
      "   MISSING FEATURES: ['NoOfMan_lag_1', 'NoOfMan_lag_2', 'NoOfMan_lag_3', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7', 'IsWeekend_feat', 'NoOfMan_rolling_max_7', 'NoOfMan_rolling_min_7', 'NoOfMan_rolling_std_7', 'NoOfMan_same_dow_lag']...\n",
      "\n",
      "3. RECENT DATA FEATURE ANALYSIS:\n",
      "   Most recent date: 2025-05-21 00:00:00\n",
      "   Actual NoOfMan: 6.86\n",
      "\n",
      "   LAG FEATURES VALUES:\n",
      "\n",
      "   ROLLING FEATURES VALUES:\n",
      "\n",
      "4. PREDICTION TRACE:\n",
      "   Input shape: (1, 32)\n",
      "   Input columns: 32\n",
      "   PREDICTION: 0.155619\n",
      "\n",
      "   PIPELINE TRACE:\n",
      "   After preprocessing shape: (1, 57)\n",
      "   Preprocessed sample values: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   Non-zero features: 1/57 (1.8%)\n",
      "   Max absolute value: 1.000000\n",
      "\n",
      "5. TRAINING DATA COMPARISON:\n",
      "   High-value training examples:\n",
      "   Date: 2019-12-12 00:00:00, NoOfMan: 39.03\n",
      "     Key lags: \n",
      "   Date: 2023-12-18 00:00:00, NoOfMan: 31.73\n",
      "     Key lags: \n",
      "   Date: 2019-12-11 00:00:00, NoOfMan: 31.04\n",
      "     Key lags: \n",
      "\n",
      "=== FEATURE GENERATION DEBUG FOR WORK TYPE 209 ===\n",
      "\n",
      "1. RAW DATA CHECK:\n",
      "   Total records: 1526\n",
      "   Date range: 2019-07-01 00:00:00 to 2025-05-21 00:00:00\n",
      "\n",
      "   Last 5 days raw data:\n",
      "   2025-05-15: 7.05125\n",
      "   2025-05-16: 6.556249999999999\n",
      "   2025-05-19: 9.0125\n",
      "   2025-05-20: 9.662500000000001\n",
      "   2025-05-21: 6.86\n",
      "\n",
      "2. MANUAL LAG CALCULATION:\n",
      "   Latest date: 2025-05-21 00:00:00\n",
      "   1-day lag (2025-05-20): 9.662500000000001\n",
      "   7-day lag (2025-05-14): 9.53\n",
      "   7-day rolling mean: 7.83\n",
      "\n",
      "3. FEATURE ENGINEERING VERIFICATION:\n",
      "   NoOfMan_lag_1: MISSING\n",
      "   NoOfMan_lag_7: MISSING\n",
      "   NoOfMan_rolling_mean_7: MISSING\n",
      "   DayOfWeek_feat: MISSING\n",
      "   Month_feat: MISSING\n",
      "   IsWeekend_feat: MISSING\n",
      "\n",
      "=== TESTING WITH KNOWN GOOD DATA ===\n",
      "\n",
      "1. TESTING WITH HIGH-VALUE PERIOD:\n",
      "   Test date: 2025-05-13 00:00:00\n",
      "   Actual NoOfMan: 11.18875\n",
      "   Predicted NoOfMan: 0.155619\n",
      "   Prediction error: 11.033131\n",
      "   Key feature values:\n",
      "\n",
      "=== DIAGNOSIS SUMMARY ===\n",
      "1. Missing features: 32 out of expected features\n",
      "2. Available features: 0\n",
      "3. CRITICAL: Missing features may be causing zero predictions\n",
      "   Key missing features to investigate: ['NoOfMan_lag_1', 'NoOfMan_lag_2', 'NoOfMan_lag_3', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7']\n",
      "\n",
      "=== RECOMMENDATIONS ===\n",
      "1. Check if feature engineering is running correctly in prediction pipeline\n",
      "2. Verify that lag features are being calculated with actual historical data\n",
      "3. Ensure the same preprocessing is applied during prediction as during training\n",
      "4. Check if productivity features (Quantity, KPIs) are available during prediction\n",
      "\n",
      "=== QUICK TEST WITH MANUAL FEATURES ===\n",
      "\n",
      "Test prediction with manual features: 0.19\n",
      "Expected range based on training data: 5-15 workers\n",
      "PROBLEM: Still getting very low prediction even with reasonable feature values!\n",
      "This suggests an issue with the model itself or feature preprocessing.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Debug script to identify why punch code 209 predictions are near zero\n",
    "despite having substantial actual values during training\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def debug_prediction_pipeline_209(df, models, work_type='209'):\n",
    "    \"\"\"\n",
    "    Comprehensive debugging of prediction pipeline for punch code 209\n",
    "    \"\"\"\n",
    "    print(f\"=== PREDICTION PIPELINE DEBUG FOR WORK TYPE {work_type} ===\\n\")\n",
    "    \n",
    "    # 1. Verify model exists and basic info\n",
    "    if work_type not in models:\n",
    "        print(f\"ERROR: No model found for work type {work_type}\")\n",
    "        return\n",
    "    \n",
    "    model = models[work_type]\n",
    "    print(f\"1. MODEL VERIFICATION:\")\n",
    "    print(f\"   Model type: {type(model)}\")\n",
    "    print(f\"   Is Pipeline: {hasattr(model, 'steps')}\")\n",
    "    \n",
    "    if hasattr(model, 'steps'):\n",
    "        print(f\"   Pipeline steps: {[step[0] for step in model.steps]}\")\n",
    "    \n",
    "    # 2. Check what features the model expects vs what we're providing\n",
    "    print(f\"\\n2. FEATURE COMPARISON:\")\n",
    "    \n",
    "    # Get expected features from model training\n",
    "    try:\n",
    "        if hasattr(model, 'feature_names_in_'):\n",
    "            expected_features = list(model.feature_names_in_)\n",
    "        elif hasattr(model.named_steps['model'], 'feature_names_in_'):\n",
    "            expected_features = list(model.named_steps['model'].feature_names_in_)\n",
    "        else:\n",
    "            expected_features = None\n",
    "        \n",
    "        print(f\"   Expected features from model: {len(expected_features) if expected_features else 'Unknown'}\")\n",
    "        if expected_features:\n",
    "            print(f\"   First 10 expected: {expected_features[:10]}\")\n",
    "    except:\n",
    "        expected_features = None\n",
    "        print(\"   Could not extract expected features from model\")\n",
    "    \n",
    "    # Get features we're actually providing\n",
    "    from utils.feature_engineering import get_feature_lists\n",
    "    numeric_features, categorical_features = get_feature_lists(\n",
    "        include_advanced_features=True, \n",
    "        include_productivity_metrics=True\n",
    "    )\n",
    "    provided_features = numeric_features + categorical_features\n",
    "    \n",
    "    print(f\"   Features we're providing: {len(provided_features)}\")\n",
    "    print(f\"   Numeric: {len(numeric_features)}, Categorical: {len(categorical_features)}\")\n",
    "    \n",
    "    # Check which features are missing in our data\n",
    "    work_data = df[df['WorkType'] == work_type].copy()\n",
    "    available_features = [f for f in provided_features if f in work_data.columns]\n",
    "    missing_features = [f for f in provided_features if f not in work_data.columns]\n",
    "    \n",
    "    print(f\"   Available in data: {len(available_features)}\")\n",
    "    print(f\"   Missing from data: {len(missing_features)}\")\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"   MISSING FEATURES: {missing_features[:10]}...\")  # Show first 10\n",
    "    \n",
    "    # 3. Examine actual feature values for recent data\n",
    "    print(f\"\\n3. RECENT DATA FEATURE ANALYSIS:\")\n",
    "    \n",
    "    # Get the most recent record\n",
    "    work_data_sorted = work_data.sort_values('Date', ascending=False)\n",
    "    recent_record = work_data_sorted.iloc[0]\n",
    "    \n",
    "    print(f\"   Most recent date: {recent_record['Date']}\")\n",
    "    print(f\"   Actual NoOfMan: {recent_record['NoOfMan']}\")\n",
    "    \n",
    "    # Check lag features specifically\n",
    "    lag_features = [f for f in available_features if 'lag' in f and 'NoOfMan' in f]\n",
    "    print(f\"\\n   LAG FEATURES VALUES:\")\n",
    "    for feature in lag_features[:8]:  # Show first 8 lag features\n",
    "        value = recent_record.get(feature, 'MISSING')\n",
    "        print(f\"   {feature}: {value}\")\n",
    "    \n",
    "    # Check rolling features\n",
    "    rolling_features = [f for f in available_features if 'rolling' in f and 'NoOfMan' in f]\n",
    "    print(f\"\\n   ROLLING FEATURES VALUES:\")\n",
    "    for feature in rolling_features[:5]:  # Show first 5 rolling features\n",
    "        value = recent_record.get(feature, 'MISSING')\n",
    "        print(f\"   {feature}: {value}\")\n",
    "    \n",
    "    # 4. Make a prediction and trace through the process\n",
    "    print(f\"\\n4. PREDICTION TRACE:\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare features for prediction\n",
    "        X_pred = work_data_sorted.iloc[[0]][available_features]\n",
    "        \n",
    "        # Add any missing columns with zeros\n",
    "        for feature in provided_features:\n",
    "            if feature not in X_pred.columns:\n",
    "                X_pred[feature] = 0.0\n",
    "        \n",
    "        print(f\"   Input shape: {X_pred.shape}\")\n",
    "        print(f\"   Input columns: {len(X_pred.columns)}\")\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(X_pred)[0]\n",
    "        print(f\"   PREDICTION: {prediction:.6f}\")\n",
    "        \n",
    "        # If it's a pipeline, trace through steps\n",
    "        if hasattr(model, 'steps'):\n",
    "            print(f\"\\n   PIPELINE TRACE:\")\n",
    "            \n",
    "            # Transform through preprocessor\n",
    "            if 'preprocessor' in [step[0] for step in model.steps]:\n",
    "                preprocessor = model.named_steps['preprocessor']\n",
    "                X_transformed = preprocessor.transform(X_pred)\n",
    "                print(f\"   After preprocessing shape: {X_transformed.shape}\")\n",
    "                print(f\"   Preprocessed sample values: {X_transformed[0][:10]}\")  # First 10 values\n",
    "                \n",
    "                # Check if all values are zero or very small\n",
    "                if isinstance(X_transformed, np.ndarray):\n",
    "                    non_zero_count = np.count_nonzero(X_transformed)\n",
    "                    total_count = X_transformed.size\n",
    "                    print(f\"   Non-zero features: {non_zero_count}/{total_count} ({non_zero_count/total_count*100:.1f}%)\")\n",
    "                    print(f\"   Max absolute value: {np.abs(X_transformed).max():.6f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ERROR in prediction: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    # 5. Compare with training data patterns\n",
    "    print(f\"\\n5. TRAINING DATA COMPARISON:\")\n",
    "    \n",
    "    # Get some high-value training examples\n",
    "    high_value_examples = work_data[work_data['NoOfMan'] > 10].sort_values('NoOfMan', ascending=False).head(3)\n",
    "    \n",
    "    print(f\"   High-value training examples:\")\n",
    "    for idx, row in high_value_examples.iterrows():\n",
    "        print(f\"   Date: {row['Date']}, NoOfMan: {row['NoOfMan']:.2f}\")\n",
    "        \n",
    "        # Show key lag features for these examples\n",
    "        key_lags = ['NoOfMan_lag_1', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7']\n",
    "        lag_values = []\n",
    "        for lag_feature in key_lags:\n",
    "            if lag_feature in row:\n",
    "                lag_values.append(f\"{lag_feature}: {row[lag_feature]:.2f}\")\n",
    "        print(f\"     Key lags: {', '.join(lag_values)}\")\n",
    "    \n",
    "    return recent_record, available_features, missing_features\n",
    "\n",
    "def debug_feature_generation_209(df, work_type='209'):\n",
    "    \"\"\"\n",
    "    Debug the feature generation process specifically\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== FEATURE GENERATION DEBUG FOR WORK TYPE {work_type} ===\\n\")\n",
    "    \n",
    "    work_data = df[df['WorkType'] == work_type].copy()\n",
    "    work_data = work_data.sort_values('Date')\n",
    "    \n",
    "    print(f\"1. RAW DATA CHECK:\")\n",
    "    print(f\"   Total records: {len(work_data)}\")\n",
    "    print(f\"   Date range: {work_data['Date'].min()} to {work_data['Date'].max()}\")\n",
    "    \n",
    "    # Check the last few days of raw data\n",
    "    print(f\"\\n   Last 5 days raw data:\")\n",
    "    last_5 = work_data.tail(5)[['Date', 'NoOfMan']]\n",
    "    for idx, row in last_5.iterrows():\n",
    "        print(f\"   {row['Date'].date()}: {row['NoOfMan']}\")\n",
    "    \n",
    "    # 2. Check lag feature calculation manually\n",
    "    print(f\"\\n2. MANUAL LAG CALCULATION:\")\n",
    "    \n",
    "    latest_date = work_data['Date'].max()\n",
    "    print(f\"   Latest date: {latest_date}\")\n",
    "    \n",
    "    # Calculate what lag features SHOULD be\n",
    "    for lag_days in [1, 7]:\n",
    "        lag_date = latest_date - timedelta(days=lag_days)\n",
    "        lag_records = work_data[work_data['Date'] == lag_date]\n",
    "        lag_value = lag_records['NoOfMan'].sum() if not lag_records.empty else 0\n",
    "        print(f\"   {lag_days}-day lag ({lag_date.date()}): {lag_value}\")\n",
    "    \n",
    "    # Calculate 7-day rolling mean manually\n",
    "    last_7_days = work_data[work_data['Date'] > latest_date - timedelta(days=7)]\n",
    "    rolling_mean = last_7_days['NoOfMan'].mean()\n",
    "    print(f\"   7-day rolling mean: {rolling_mean:.2f}\")\n",
    "    \n",
    "    # 3. Check if feature engineering is working correctly\n",
    "    print(f\"\\n3. FEATURE ENGINEERING VERIFICATION:\")\n",
    "    \n",
    "    # Check if we have the required columns after feature engineering\n",
    "    required_columns = ['NoOfMan_lag_1', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7', \n",
    "                       'DayOfWeek_feat', 'Month_feat', 'IsWeekend_feat']\n",
    "    \n",
    "    for col in required_columns:\n",
    "        if col in work_data.columns:\n",
    "            latest_value = work_data[col].iloc[-1] if len(work_data) > 0 else \"N/A\"\n",
    "            print(f\"   {col}: {latest_value}\")\n",
    "        else:\n",
    "            print(f\"   {col}: MISSING\")\n",
    "    \n",
    "    return work_data\n",
    "\n",
    "def test_prediction_with_known_good_data(df, models, work_type='209'):\n",
    "    \"\"\"\n",
    "    Test prediction using data that should give good results\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== TESTING WITH KNOWN GOOD DATA ===\\n\")\n",
    "    \n",
    "    work_data = df[df['WorkType'] == work_type].copy()\n",
    "    work_data = work_data.sort_values('Date')\n",
    "    \n",
    "    # Find a period where we had consistently high values\n",
    "    high_periods = work_data[work_data['NoOfMan'] > 10]\n",
    "    \n",
    "    if len(high_periods) > 0:\n",
    "        print(f\"1. TESTING WITH HIGH-VALUE PERIOD:\")\n",
    "        \n",
    "        # Take a record from a high-value period\n",
    "        test_record = high_periods.iloc[-1]  # Last high-value record\n",
    "        print(f\"   Test date: {test_record['Date']}\")\n",
    "        print(f\"   Actual NoOfMan: {test_record['NoOfMan']}\")\n",
    "        \n",
    "        # Get available features\n",
    "        from utils.feature_engineering import get_feature_lists\n",
    "        numeric_features, categorical_features = get_feature_lists(\n",
    "            include_advanced_features=True, \n",
    "            include_productivity_metrics=True\n",
    "        )\n",
    "        available_features = [f for f in numeric_features + categorical_features if f in work_data.columns]\n",
    "        \n",
    "        # Prepare for prediction\n",
    "        X_test = pd.DataFrame([test_record])[available_features]\n",
    "        \n",
    "        # Add missing features with zeros\n",
    "        all_features = numeric_features + categorical_features\n",
    "        for feature in all_features:\n",
    "            if feature not in X_test.columns:\n",
    "                X_test[feature] = 0.0\n",
    "        \n",
    "        # Make prediction\n",
    "        model = models[work_type]\n",
    "        prediction = model.predict(X_test)[0]\n",
    "        \n",
    "        print(f\"   Predicted NoOfMan: {prediction:.6f}\")\n",
    "        print(f\"   Prediction error: {abs(test_record['NoOfMan'] - prediction):.6f}\")\n",
    "        \n",
    "        # Show key feature values for this record\n",
    "        key_features = ['NoOfMan_lag_1', 'NoOfMan_lag_7', 'NoOfMan_rolling_mean_7']\n",
    "        print(f\"   Key feature values:\")\n",
    "        for feature in key_features:\n",
    "            if feature in test_record:\n",
    "                print(f\"     {feature}: {test_record[feature]:.2f}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"   No high-value periods found for testing\")\n",
    "\n",
    "def comprehensive_debug_209(data_path, models_path):\n",
    "    \"\"\"\n",
    "    Run all debugging functions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        if data_path.endswith('.csv'):\n",
    "            df = pd.read_csv(data_path)\n",
    "        else:\n",
    "            df = pd.read_excel(data_path)\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        if 'PunchCode' in df.columns:\n",
    "            df = df.rename(columns={'PunchCode': 'WorkType'})\n",
    "        df['WorkType'] = df['WorkType'].astype(str)\n",
    "        \n",
    "        # Load models\n",
    "        print(\"Loading models...\")\n",
    "        with open(models_path, 'rb') as f:\n",
    "            models = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(models)} models\")\n",
    "        \n",
    "        if '209' not in models:\n",
    "            print(\"ERROR: No model found for punch code 209!\")\n",
    "            return\n",
    "        \n",
    "        # Run all debug functions\n",
    "        recent_record, available_features, missing_features = debug_prediction_pipeline_209(df, models, '209')\n",
    "        work_data = debug_feature_generation_209(df, '209')\n",
    "        test_prediction_with_known_good_data(df, models, '209')\n",
    "        \n",
    "        # Final recommendations\n",
    "        print(f\"\\n=== DIAGNOSIS SUMMARY ===\")\n",
    "        print(f\"1. Missing features: {len(missing_features)} out of expected features\")\n",
    "        print(f\"2. Available features: {len(available_features)}\")\n",
    "        \n",
    "        if missing_features:\n",
    "            print(f\"3. CRITICAL: Missing features may be causing zero predictions\")\n",
    "            print(f\"   Key missing features to investigate: {missing_features[:5]}\")\n",
    "        \n",
    "        print(f\"\\n=== RECOMMENDATIONS ===\")\n",
    "        print(f\"1. Check if feature engineering is running correctly in prediction pipeline\")\n",
    "        print(f\"2. Verify that lag features are being calculated with actual historical data\") \n",
    "        print(f\"3. Ensure the same preprocessing is applied during prediction as during training\")\n",
    "        print(f\"4. Check if productivity features (Quantity, KPIs) are available during prediction\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in comprehensive debug: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Quick fix to test if the issue is missing features\n",
    "def quick_test_with_manual_features(models, work_type='209'):\n",
    "    \"\"\"\n",
    "    Test prediction with manually created features based on the training data patterns\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== QUICK TEST WITH MANUAL FEATURES ===\\n\")\n",
    "    \n",
    "    if work_type not in models:\n",
    "        print(f\"No model for {work_type}\")\n",
    "        return\n",
    "    \n",
    "    model = models[work_type]\n",
    "    \n",
    "    # Create a test case with reasonable lag values based on the training data\n",
    "    # (mean was 8.56, so let's use values around that)\n",
    "    test_features = {\n",
    "        'NoOfMan_lag_1': 8.0,\n",
    "        'NoOfMan_lag_2': 7.5,\n",
    "        'NoOfMan_lag_3': 9.0,\n",
    "        'NoOfMan_lag_7': 8.5,\n",
    "        'NoOfMan_lag_14': 8.0,\n",
    "        'NoOfMan_lag_30': 7.8,\n",
    "        'NoOfMan_rolling_mean_7': 8.2,\n",
    "        'NoOfMan_rolling_max_7': 12.0,\n",
    "        'NoOfMan_rolling_min_7': 5.0,\n",
    "        'NoOfMan_rolling_std_7': 2.0,\n",
    "        'NoOfMan_same_dow_lag': 8.0,\n",
    "        'NoOfMan_7day_trend': 0.5,\n",
    "        'NoOfMan_1day_trend': 0.2,\n",
    "        'DayOfWeek_feat': 1,  # Tuesday\n",
    "        'Month_feat': 5,      # May\n",
    "        'IsWeekend_feat': 0,  # Not weekend\n",
    "        'Year_feat': 2025,\n",
    "        'Quarter': 2\n",
    "    }\n",
    "    \n",
    "    # Add productivity features with reasonable values\n",
    "    productivity_features = {\n",
    "        'Quantity_lag_1': 1000,\n",
    "        'Quantity_lag_7': 950,\n",
    "        'Quantity_rolling_mean_7': 980,\n",
    "        'Quantity_per_Worker': 120,\n",
    "        'Combined_KPI_lag_1': 0.85,\n",
    "        'ResourceKPI_lag_1': 0.82,\n",
    "        'SystemKPI_lag_1': 0.88,\n",
    "        'Hours_SystemHours_Ratio_lag_1': 1.1,\n",
    "        'Workers_Predicted_from_Quantity': 8.3\n",
    "    }\n",
    "    \n",
    "    test_features.update(productivity_features)\n",
    "    \n",
    "    # Get all expected features and set missing ones to 0\n",
    "    from utils.feature_engineering import get_feature_lists\n",
    "    numeric_features, categorical_features = get_feature_lists(\n",
    "        include_advanced_features=True, \n",
    "        include_productivity_metrics=True\n",
    "    )\n",
    "    \n",
    "    all_expected_features = numeric_features + categorical_features\n",
    "    \n",
    "    for feature in all_expected_features:\n",
    "        if feature not in test_features:\n",
    "            test_features[feature] = 0.0\n",
    "    \n",
    "    # Create DataFrame and predict\n",
    "    X_test = pd.DataFrame([test_features])\n",
    "    \n",
    "    try:\n",
    "        prediction = model.predict(X_test)[0]\n",
    "        print(f\"Test prediction with manual features: {prediction:.2f}\")\n",
    "        print(f\"Expected range based on training data: 5-15 workers\")\n",
    "        \n",
    "        if prediction < 1.0:\n",
    "            print(\"PROBLEM: Still getting very low prediction even with reasonable feature values!\")\n",
    "            print(\"This suggests an issue with the model itself or feature preprocessing.\")\n",
    "        else:\n",
    "            print(\"SUCCESS: Manual features produce reasonable prediction.\")\n",
    "            print(\"Issue is likely in feature generation during actual prediction.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in manual test: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual paths\n",
    "    data_path = \"C:/forlogssystems/work_utilization_app/209.xlsx\" \n",
    "    models_path = \"C:/forlogssystems/Models/work_utilization_models.pkl\" \n",
    "    \n",
    "    # Run comprehensive debugging\n",
    "    success = comprehensive_debug_209(data_path, models_path)\n",
    "    \n",
    "    if success:\n",
    "        # Load models for quick test\n",
    "        with open(models_path, 'rb') as f:\n",
    "            models = pickle.load(f)\n",
    "        \n",
    "        # Test with manual features\n",
    "        quick_test_with_manual_features(models, '209')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
